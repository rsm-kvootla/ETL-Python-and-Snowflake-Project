{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ETL Snowflake and Python Project - Supplier (PGSQL) , Purchase Order (CSV), Invoice (XML) and Weather Data (NOAA) **\n",
    "- Alexa Gamble\n",
    "- Anjana Khabir\n",
    "- Kai Stern\n",
    "- Kowsalya Nitya Vootla \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to Snowflake account\n",
    "import snowflake.connector\n",
    "import os\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user='NKVOOTLA',\n",
    "    password='ABCD1234cool***',\n",
    "    account='qblwawb-idb43915'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define cursor and create warehouse and database\n",
    "cs = conn.cursor()\n",
    "cs.execute(\"CREATE WAREHOUSE IF NOT EXISTS Group3_ETL_project_warehouse\")\n",
    "\n",
    "cs.execute(\"CREATE DATABASE IF NOT EXISTS Group3_ETL_project_database\")\n",
    "\n",
    "cs.execute(\"USE DATABASE Group3_ETL_project_database\")\n",
    "\n",
    "cs.execute(\"CREATE SCHEMA IF NOT EXISTS Group3_ETL_project_schema\")\n",
    "\n",
    "cs.execute(\"USE SCHEMA Group3_ETL_project_schema\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1 and Question 2**\n",
    "\n",
    "- Note: We have used the updated `2022-2.csv` file shared in the announcement.\n",
    "- We removed the columns `comments` and `internal comments` since they only have null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a file format for CSV called CSV_FORMAT_NAME\n",
    "create_format_query = \"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT CSV_FORMAT_NAME\n",
    "TYPE = 'CSV'\n",
    "FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "SKIP_HEADER = 1\n",
    "FIELD_DELIMITER = ','\n",
    "EMPTY_FIELD_AS_NULL = TRUE\n",
    "NULL_IF = ('', 'NULL')\n",
    "TIMESTAMP_FORMAT = 'MM/DD/YYYY HH24:MI';\n",
    "\"\"\"\n",
    "cs.execute(create_format_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a stage to load the csv files\n",
    "create_stage_query = \"\"\"\n",
    "CREATE OR REPLACE STAGE purchase_orders_stage\n",
    "FILE_FORMAT = 'CSV_FORMAT_NAME';\n",
    "\"\"\"\n",
    "cs.execute(create_stage_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to upload file: Monthly PO Data/2019-1.csv\n",
      "Attempting to upload file: Monthly PO Data/2019-10.csv\n",
      "Attempting to upload file: Monthly PO Data/2019-11.csv\n",
      "Attempting to upload file: Monthly PO Data/2019-12.csv\n",
      "Attempting to upload file: Monthly PO Data/2019-2.csv\n",
      "Attempting to upload file: Monthly PO Data/2019-3.csv\n",
      "Attempting to upload file: Monthly PO Data/2019-4.csv\n",
      "Attempting to upload file: Monthly PO Data/2019-5.csv\n",
      "Attempting to upload file: Monthly PO Data/2019-6.csv\n",
      "Attempting to upload file: Monthly PO Data/2019-7.csv\n",
      "Attempting to upload file: Monthly PO Data/2019-8.csv\n",
      "Attempting to upload file: Monthly PO Data/2019-9.csv\n",
      "Attempting to upload file: Monthly PO Data/2020-1.csv\n",
      "Attempting to upload file: Monthly PO Data/2020-10.csv\n",
      "Attempting to upload file: Monthly PO Data/2020-11.csv\n",
      "Attempting to upload file: Monthly PO Data/2020-12.csv\n",
      "Attempting to upload file: Monthly PO Data/2020-2.csv\n",
      "Attempting to upload file: Monthly PO Data/2020-3.csv\n",
      "Attempting to upload file: Monthly PO Data/2020-4.csv\n",
      "Attempting to upload file: Monthly PO Data/2020-5.csv\n",
      "Attempting to upload file: Monthly PO Data/2020-6.csv\n",
      "Attempting to upload file: Monthly PO Data/2020-7.csv\n",
      "Attempting to upload file: Monthly PO Data/2020-8.csv\n",
      "Attempting to upload file: Monthly PO Data/2020-9.csv\n",
      "Attempting to upload file: Monthly PO Data/2021-1.csv\n",
      "Attempting to upload file: Monthly PO Data/2021-10.csv\n",
      "Attempting to upload file: Monthly PO Data/2021-11.csv\n",
      "Attempting to upload file: Monthly PO Data/2021-12.csv\n",
      "Attempting to upload file: Monthly PO Data/2021-2.csv\n",
      "Attempting to upload file: Monthly PO Data/2021-3.csv\n",
      "Attempting to upload file: Monthly PO Data/2021-4.csv\n",
      "Attempting to upload file: Monthly PO Data/2021-5.csv\n",
      "Attempting to upload file: Monthly PO Data/2021-6.csv\n",
      "Attempting to upload file: Monthly PO Data/2021-7.csv\n",
      "Attempting to upload file: Monthly PO Data/2021-8.csv\n",
      "Attempting to upload file: Monthly PO Data/2021-9.csv\n",
      "Attempting to upload file: Monthly PO Data/2022-1.csv\n",
      "Attempting to upload file: Monthly PO Data/2022-2.csv\n",
      "Attempting to upload file: Monthly PO Data/2022-3.csv\n",
      "Attempting to upload file: Monthly PO Data/2022-4.csv\n",
      "Attempting to upload file: Monthly PO Data/2022-5.csv\n"
     ]
    }
   ],
   "source": [
    "#Load files into the stage using glob\n",
    "\n",
    "import glob\n",
    "csv_files_path = \"Monthly PO Data\" # Path to the directory containing the CSV files assuming we are in data directory\n",
    "\n",
    "for year in [2019, 2020, 2021, 2022]:\n",
    "    for file_path in glob.glob(os.path.join(csv_files_path, f'{year}-[0-9]*.csv')):\n",
    "        # Handle backslashes and print the file path\n",
    "        normalized_file_path = file_path.replace('\\\\', '/')\n",
    "        print(f\"Attempting to upload file: {normalized_file_path}\")\n",
    "\n",
    "        put_query = f\"PUT 'file://{normalized_file_path}' @purchase_orders_stage;\"\n",
    "        \n",
    "        try:\n",
    "            cs.execute(put_query)\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading file {os.path.basename(file_path)}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Create staging table for purchase orders\n",
    "create_staging_table_query = \"\"\"\n",
    "CREATE OR REPLACE TABLE purchase_orders_staging_table(\n",
    "    PurchaseOrderID INTEGER,\n",
    "    SupplierID INTEGER,\n",
    "    OrderDate DATE,\n",
    "    DeliveryMethodID INTEGER,\n",
    "    ContactPersonID INTEGER,\n",
    "    ExpectedDeliveryDate DATE,\n",
    "    SupplierReference VARCHAR(16777216),\n",
    "    IsOrderFinalized INTEGER,\n",
    "    Comments TEXT,\n",
    "    InternalComments TEXT,\n",
    "    LastEditedBy INTEGER,\n",
    "    LastEditedWhen STRING,\n",
    "    PurchaseOrderLineID INTEGER,\n",
    "    StockItemID INTEGER,\n",
    "    OrderedOuters INTEGER,\n",
    "    Description TEXT,\n",
    "    ReceivedOuters INTEGER,\n",
    "    PackageTypeID INTEGER,\n",
    "    ExpectedUnitPricePerOuter FLOAT,\n",
    "    LastReceiptDate DATE,\n",
    "    IsOrderLineFinalized INTEGER,\n",
    "    Right_LastEditedBy INTEGER,\n",
    "    Right_LastEditedWhen STRING\n",
    ")\n",
    "\"\"\"\n",
    "cs.execute(create_staging_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from the purchase orders stage into the purchase orders stage table\n",
    "load_data_query = \"\"\"\n",
    "COPY INTO purchase_orders_staging_table\n",
    "FROM @purchase_orders_stage\n",
    "FILE_FORMAT = (FORMAT_NAME = 'CSV_FORMAT_NAME')\n",
    "ON_ERROR = 'ABORT_STATEMENT';\n",
    "\"\"\"\n",
    "cs.execute(load_data_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data from purchase_orders_staging_table:\n",
      "(106, 4, datetime.date(2019, 3, 1), 7, 2, datetime.date(2019, 3, 21), '293092', 1, None, None, 4, '3/4/2019 7:00', 469, 77, 92, '\"The Gu\" red shirt XML tag t-shirt (White) XXS', 92, 6, 84.0, datetime.date(2019, 3, 4), 1, 4, '3/4/2019 7:00')\n",
      "(106, 4, datetime.date(2019, 3, 1), 7, 2, datetime.date(2019, 3, 21), '293092', 1, None, None, 4, '3/4/2019 7:00', 470, 78, 127, '\"The Gu\" red shirt XML tag t-shirt (White) XS', 127, 6, 84.0, datetime.date(2019, 3, 4), 1, 4, '3/4/2019 7:00')\n",
      "(106, 4, datetime.date(2019, 3, 1), 7, 2, datetime.date(2019, 3, 21), '293092', 1, None, None, 4, '3/4/2019 7:00', 471, 80, 20, '\"The Gu\" red shirt XML tag t-shirt (White) M', 20, 6, 84.0, datetime.date(2019, 3, 4), 1, 4, '3/4/2019 7:00')\n",
      "(106, 4, datetime.date(2019, 3, 1), 7, 2, datetime.date(2019, 3, 21), '293092', 1, None, None, 4, '3/4/2019 7:00', 472, 86, 74, '\"The Gu\" red shirt XML tag t-shirt (White) 5XL', 74, 6, 96.0, datetime.date(2019, 3, 4), 1, 4, '3/4/2019 7:00')\n",
      "(106, 4, datetime.date(2019, 3, 1), 7, 2, datetime.date(2019, 3, 21), '293092', 1, None, None, 4, '3/4/2019 7:00', 473, 95, 22, '\"The Gu\" red shirt XML tag t-shirt (Black) XL', 22, 6, 90.0, datetime.date(2019, 3, 4), 1, 4, '3/4/2019 7:00')\n"
     ]
    }
   ],
   "source": [
    "# Verify staging table creation and data load\n",
    "try:\n",
    "    cs.execute(\"SELECT * FROM purchase_orders_staging_table LIMIT 5\")\n",
    "    print(\"Sample data from purchase_orders_staging_table:\")\n",
    "    for row in cs.fetchall():\n",
    "        print(row)\n",
    "except Exception as e:\n",
    "    print(f\"Error verifying staging table: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create final table for purchase orders\n",
    "#POAmount is added to the table to store the total amount of the purchase order for question 2\n",
    "create_final_table_query = \"\"\"\n",
    "CREATE OR REPLACE TABLE purchase_orders_table (\n",
    "    PurchaseOrderID INTEGER,\n",
    "    SupplierID INTEGER,\n",
    "    OrderDate DATE,\n",
    "    DeliveryMethodID INTEGER,\n",
    "    ContactPersonID INTEGER,\n",
    "    ExpectedDeliveryDate DATE,\n",
    "    SupplierReference VARCHAR(16777216),\n",
    "    IsOrderFinalized INTEGER,\n",
    "    LastEditedBy INTEGER,\n",
    "    LastEditedWhen TIMESTAMP,\n",
    "    PurchaseOrderLineID INTEGER,\n",
    "    StockItemID INTEGER,\n",
    "    OrderedOuters INTEGER,\n",
    "    Description TEXT,\n",
    "    ReceivedOuters INTEGER,\n",
    "    PackageTypeID INTEGER,\n",
    "    ExpectedUnitPricePerOuter FLOAT,\n",
    "    LastReceiptDate DATE,\n",
    "    IsOrderLineFinalized INTEGER,\n",
    "    Right_LastEditedBy INTEGER,\n",
    "    Right_LastEditedWhen TIMESTAMP,\n",
    "    POAmount INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "cs.execute(create_final_table_query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert data from purchase orders staging table to final table with proper date and timestamp conversions. \n",
    "#For question 2 we added a column POAmount which is the total amount of the purchase order, which is calculated by multiplying ExpectedUnitPricePerOuter and OrderedOuters and summing them up for each PurchaseOrderID.\n",
    "#We used a LEFT JOIN to join the staging table with the subquery that calculates the POAmount for each PurchaseOrderID.\n",
    "convert_and_load_query = \"\"\"\n",
    "INSERT INTO purchase_orders_table\n",
    "SELECT \n",
    "    PurchaseOrderID,\n",
    "    SupplierID,\n",
    "    OrderDate,\n",
    "    DeliveryMethodID,\n",
    "    ContactPersonID,\n",
    "    ExpectedDeliveryDate,\n",
    "    SupplierReference,\n",
    "    IsOrderFinalized,\n",
    "    LastEditedBy,\n",
    "    CASE \n",
    "        WHEN TRY_TO_TIMESTAMP(LastEditedWhen, 'MM/DD/YYYY HH24:MI:SS') IS NOT NULL THEN TRY_TO_TIMESTAMP(LastEditedWhen, 'MM/DD/YYYY HH24:MI')\n",
    "        WHEN TRY_TO_TIMESTAMP(LastEditedWhen, 'MM/DD/YYYY HH24:MI') IS NOT NULL THEN TRY_TO_TIMESTAMP(LastEditedWhen, 'MM/DD/YYYY HH24:MI')\n",
    "        ELSE NULL\n",
    "    END AS LastEditedWhen,\n",
    "    PurchaseOrderLineID,\n",
    "    StockItemID,\n",
    "    OrderedOuters,\n",
    "    Description,\n",
    "    ReceivedOuters,\n",
    "    PackageTypeID,\n",
    "    ExpectedUnitPricePerOuter,\n",
    "    LastReceiptDate,\n",
    "    IsOrderLineFinalized,\n",
    "    Right_LastEditedBy,\n",
    "    CASE \n",
    "        WHEN TRY_TO_TIMESTAMP(Right_LastEditedWhen, 'MM/DD/YYYY HH24:MI:SS') IS NOT NULL THEN TRY_TO_TIMESTAMP(Right_LastEditedWhen, 'MM/DD/YYYY HH24:MI')\n",
    "        WHEN TRY_TO_TIMESTAMP(Right_LastEditedWhen, 'MM/DD/YYYY HH24:MI') IS NOT NULL THEN TRY_TO_TIMESTAMP(Right_LastEditedWhen, 'MM/DD/YYYY HH24:MI')\n",
    "        ELSE NULL\n",
    "    END AS Right_LastEditedWhen,\n",
    "    POAmount\n",
    "FROM purchase_orders_staging_table\n",
    "LEFT JOIN (SELECT PurchaseOrderID AS POID, SUM(ExpectedUnitPricePerOuter * OrderedOuters) AS POAmount FROM purchase_orders_staging_table GROUP BY PurchaseOrderID) ON purchase_orders_staging_table.PurchaseOrderID = POID;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    cs.execute(convert_and_load_query)\n",
    "except Exception as e:\n",
    "    print(f\"Error converting and loading data: {e}\")\n",
    "\n",
    "# This table creates 22 Columns (1 column (PO Amount) is for question 2 and 8367 rows\n",
    "\n",
    "#cs.execute(\"SELECT COUNT(*) FROM purchase_orders_table\")\n",
    "#row_count = cs.fetchone()[0]\n",
    "#print(f\"Number of rows in purchase_orders_table: {row_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a stage for the XML file\n",
    "create_xml_stage_query = \"CREATE OR REPLACE STAGE supplier_transactions_xml_stage;\"\n",
    "cs.execute(create_xml_stage_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a file format for XML called XML_FORMAT_NAME\n",
    "create_xml_format_query = \"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT xml_format_test\n",
    "TYPE = 'XML'\n",
    "COMPRESSION = 'AUTO'\n",
    "STRIP_OUTER_ELEMENT = TRUE;\n",
    "\"\"\" \n",
    "\n",
    "cs.execute(create_xml_format_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the XML file into the stage\n",
    "file_path = 'Supplier Transactions XML.xml'  #Using relative path assuming we are on the data directory\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    put_command = f\"PUT 'file://{file_path}' @supplier_transactions_xml_stage OVERWRITE=TRUE;\"\n",
    "    cs.execute(put_command)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"The file {file_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a staging table for the XML file\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE supplier_transactions_xml_staging_table (\n",
    "    raw_data VARIANT\n",
    ");\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Copy the data from the XML file into the staging table\n",
    "cs.execute(\"\"\"\n",
    "COPY INTO supplier_transactions_xml_staging_table(raw_data)\n",
    "FROM @supplier_transactions_xml_stage\n",
    "FILE_FORMAT = (FORMAT_NAME = 'xml_format_test')\n",
    "ON_ERROR = 'CONTINUE';\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create final table for supplier transactions\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE supplier_transactions (\n",
    "    SupplierTransactionID INT,\n",
    "    SupplierID INT,\n",
    "    TransactionTypeID INT,\n",
    "    PurchaseOrderID INT,\n",
    "    PaymentMethodID INT,\n",
    "    SupplierInvoiceNumber STRING,\n",
    "    TransactionDate DATE,\n",
    "    AmountExcludingTax FLOAT,\n",
    "    TaxAmount FLOAT,\n",
    "    TransactionAmount FLOAT,\n",
    "    OutstandingBalance FLOAT,\n",
    "    FinalizationDate DATE,\n",
    "    IsFinalized BOOLEAN,\n",
    "    LastEditedBy INT,\n",
    "    LastEditedWhen TIMESTAMP\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Insert data from the staging table to the final table\n",
    "insert_xml_data_query = \"\"\"\n",
    "INSERT INTO supplier_transactions (\n",
    "    SupplierTransactionID,\n",
    "    SupplierID,\n",
    "    TransactionTypeID,\n",
    "    PurchaseOrderID,\n",
    "    PaymentMethodID,\n",
    "    SupplierInvoiceNumber,\n",
    "    TransactionDate,\n",
    "    AmountExcludingTax,\n",
    "    TaxAmount,\n",
    "    TransactionAmount,\n",
    "    OutstandingBalance,\n",
    "    FinalizationDate,\n",
    "    IsFinalized,\n",
    "    LastEditedBy,\n",
    "    LastEditedWhen\n",
    ")\n",
    "SELECT\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'SupplierTransactionID' THEN TRY_CAST(json_element.value['$']::STRING AS NUMBER) END) AS SupplierTransactionID,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'SupplierID' THEN TRY_CAST(json_element.value['$']::STRING AS NUMBER) END) AS SupplierID,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'TransactionTypeID' THEN TRY_CAST(json_element.value['$']::STRING AS NUMBER) END) AS TransactionTypeID,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'PurchaseOrderID' THEN TRY_CAST(json_element.value['$']::STRING AS NUMBER) END) AS PurchaseOrderID,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'PaymentMethodID' THEN TRY_CAST(json_element.value['$']::STRING AS NUMBER) END) AS PaymentMethodID,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'SupplierInvoiceNumber' THEN json_element.value['$']::STRING END) AS SupplierInvoiceNumber,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'TransactionDate' THEN TRY_TO_DATE(NULLIF(json_element.value['$']::STRING, ''), 'YYYY-MM-DD') END) AS TransactionDate,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'AmountExcludingTax' THEN TRY_CAST(json_element.value['$']::STRING AS FLOAT) END) AS AmountExcludingTax,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'TaxAmount' THEN TRY_CAST(json_element.value['$']::STRING AS FLOAT) END) AS TaxAmount,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'TransactionAmount' THEN TRY_CAST(json_element.value['$']::STRING AS FLOAT) END) AS TransactionAmount,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'OutstandingBalance' THEN TRY_CAST(json_element.value['$']::STRING AS FLOAT) END) AS OutstandingBalance,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'FinalizationDate' THEN TRY_TO_DATE(NULLIF(json_element.value['$']::STRING, ''), 'YYYY-MM-DD') END) AS FinalizationDate,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'IsFinalized' THEN TRY_CAST(json_element.value['$']::STRING AS NUMBER) END) AS IsFinalized,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'LastEditedBy' THEN TRY_CAST(json_element.value['$']::STRING AS NUMBER) END) AS LastEditedBy,\n",
    "    MAX(CASE WHEN json_element.value['@']::STRING = 'LastEditedWhen' THEN TRY_TO_TIMESTAMP_NTZ(NULLIF(json_element.value['$']::STRING, ''), 'YYYY-MM-DD HH24:MI:SS.FF') END) AS LastEditedWhen\n",
    "FROM Group3_ETL_project_schema.supplier_transactions_xml_staging_table,\n",
    "LATERAL FLATTEN(input => RAW_DATA) AS xml_row,\n",
    "LATERAL FLATTEN(input => xml_row.value) AS json_element\n",
    "GROUP BY xml_row.seq;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "cs.execute(insert_xml_data_query)\n",
    "\n",
    "\n",
    "#This table has 15 columns and 2.4k rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join the tables from step 2, purchase_orders_table with the poamount column and supplier_transactions, Called PODATA_TRANSACTIONS\n",
    "create_table_query_pot = \"\"\"\n",
    "CREATE OR REPLACE TABLE podata_transactions AS\n",
    "SELECT \n",
    "    A.*, \n",
    "    B.SupplierTransactionID,\n",
    "    B.TransactionTypeID,\n",
    "    B.PaymentMethodID,\n",
    "    B.SupplierInvoiceNumber,\n",
    "    B.TransactionDate,\n",
    "    B.AmountExcludingTax,\n",
    "    B.TaxAmount,\n",
    "    B.TransactionAmount,\n",
    "    B.OutstandingBalance,\n",
    "    B.FinalizationDate,\n",
    "    B.IsFinalized,\n",
    "    B.LastEditedBy AS SupplierTransactionLastEditedBy,\n",
    "    B.LastEditedWhen AS SupplierTransactionLastEditedWhen\n",
    "FROM \n",
    "    PURCHASE_ORDERS_TABLE A\n",
    "LEFT JOIN \n",
    "    SUPPLIER_TRANSACTIONS B\n",
    "ON \n",
    "    A.PurchaseOrderID = B.PurchaseOrderID AND A.SupplierID = B.SupplierID;\n",
    "\"\"\"\n",
    "\n",
    "cs.execute(create_table_query_pot)\n",
    "\n",
    "#This column has 8.4k rows and 35 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create materialized view named purchase_orders_and_invoices to find the difference between POAmount and AmountExcludingTax\n",
    "create_materialized_view_po_invoices = \"\"\"\n",
    "CREATE OR REPLACE MATERIALIZED VIEW purchase_orders_and_invoices AS\n",
    "SELECT \n",
    "    *, \n",
    "    (POAmount - AmountExcludingTax) AS invoice_vs_quoted\n",
    "FROM \n",
    "    podata_transactions;\n",
    "\"\"\"\n",
    "cs.execute(create_materialized_view_po_invoices)\n",
    "\n",
    "#This view has 8.4k rows and 36 columns. It is to be noted that the difference between POAmount and AmountExcludingTax is either 0 or marginal from the data observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL script in supplier_case.pgsql executed successfully.\n"
     ]
    }
   ],
   "source": [
    "#Adding the postgres file into the WestCoastImporters database\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "sql_file_path = \"supplier_case.pgsql\" #assuming we are on data directory\n",
    "\n",
    "def execute_pgsql_file(dbname, user, password, host, port):\n",
    "    try: \n",
    "        conn = psycopg2.connect(dbname=dbname, user=user, password=password, host=host, port=port)\n",
    "        cs = conn.cursor()\n",
    "    \n",
    "        with open(sql_file_path, 'r') as a:\n",
    "            sql = a.read()\n",
    "        cs.execute(sql)\n",
    "        conn.commit()\n",
    "    \n",
    "        print(f\"SQL script in {sql_file_path} executed successfully.\")\n",
    "    \n",
    "    except Exception as b:\n",
    "        print(f\"Error: {str(b)}\")\n",
    "    finally:\n",
    "        cs.close()\n",
    "        conn.close()\n",
    "\n",
    "execute_pgsql_file(\n",
    "    dbname=\"WestCoastImporters\",\n",
    "    user=\"jovyan\",\n",
    "    password=\"postgres\",\n",
    "    host=\"127.0.0.1\",\n",
    "    port=\"8765\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported successfully to supplier_case.csv\n"
     ]
    }
   ],
   "source": [
    "#Export the data from the supplier_case table on the WestCoastImporters database to a CSV file in our current directory (Data)\n",
    "\n",
    "import csv\n",
    "\n",
    "def export_data_to_csv():\n",
    "    try:\n",
    "        # Connect to your PostgreSQL DB\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=\"WestCoastImporters\", \n",
    "            user=\"jovyan\", \n",
    "            password=\"postgres\", \n",
    "            host=\"127.0.0.1\", \n",
    "            port=\"8765\"\n",
    "        )\n",
    "        cs = conn.cursor()\n",
    "\n",
    "        # Fetch the data and column names\n",
    "        cs.execute(\"SELECT * FROM supplier_case\")\n",
    "        rows = cs.fetchall()\n",
    "        col_names = [desc[0] for desc in cs.description]\n",
    "\n",
    "        # Open a file for writing, within data directory, assumed to be our current directory\n",
    "        with open('supplier_case.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n",
    "            # Write the column headers\n",
    "            writer.writerow(col_names)\n",
    "            # Write the data rows\n",
    "            writer.writerows(rows)\n",
    "\n",
    "        print(\"Data exported successfully to supplier_case.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        if 'cs' in locals():\n",
    "            cs.close()\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "\n",
    "export_data_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully into Snowflake table supplier_case_table\n"
     ]
    }
   ],
   "source": [
    "#Upload the created csv file to Snowflake\n",
    "def upload_csv_to_snowflake():\n",
    "    cs = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Create a stage if not already done\n",
    "        cs.execute(\"CREATE OR REPLACE STAGE supplier_case_stage\")\n",
    "        \n",
    "        # Upload the file to the stage\n",
    "        cs.execute(\"PUT file://supplier_case.csv @supplier_case_stage\")\n",
    "\n",
    "        # Create table if not exists\n",
    "        cs.execute(\"\"\"\n",
    "        CREATE OR REPLACE TABLE supplier_case_table (\n",
    "            SupplierID INTEGER,\n",
    "            \"SupplierName\" VARCHAR,\n",
    "            SupplierCategoryID INTEGER,\n",
    "            PrimaryContactPersonID INTEGER,\n",
    "            AlternateContactPersonID INTEGER,\n",
    "            DeliveryMethodID INTEGER,\n",
    "            PostalCityID INTEGER,\n",
    "            \"SupplierReference\" VARCHAR,\n",
    "            \"BankAccountName\" VARCHAR,\n",
    "            \"BankAccountBranch\" VARCHAR,\n",
    "            BankAccountCode INTEGER,\n",
    "            BankAccountNumber NUMERIC,\n",
    "            BankInternationalCode INTEGER,\n",
    "            PaymentDays INTEGER,\n",
    "            InternalComments VARCHAR,\n",
    "            \"PhoneNumber\" VARCHAR,\n",
    "            \"FaxNumber\" VARCHAR,\n",
    "            \"WebsiteURL\" VARCHAR,\n",
    "            DeliveryAddressLine1 VARCHAR,\n",
    "            DeliveryAddressLine2 VARCHAR,\n",
    "            DeliveryPostalCode INTEGER,\n",
    "            DeliveryLocation VARCHAR,\n",
    "            PostalAddressLine1 VARCHAR,\n",
    "            PostalAddressLine2 VARCHAR,\n",
    "            PostalPostalCode INTEGER,\n",
    "            LastEditedBy INTEGER,\n",
    "            ValidFrom VARCHAR,\n",
    "            ValidTo VARCHAR\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        # Copy the data from the stage into the table\n",
    "        cs.execute(\"\"\"\n",
    "            COPY INTO supplier_case_table\n",
    "            FROM @supplier_case_stage/supplier_case.csv\n",
    "            FILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY='\"' SKIP_HEADER = 1)\n",
    "        \"\"\")\n",
    "\n",
    "        print(\"Data loaded successfully into Snowflake table supplier_case_table\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "upload_csv_to_snowflake()\n",
    "\n",
    "#The supplier case table has 13 rows and 28 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully into Snowflake table US_GZN_table\n"
     ]
    }
   ],
   "source": [
    "#Upload the US 2021 Gazetteer txt file to Snowflake\n",
    "\n",
    "def upload_txt_to_snowflake():\n",
    "    try:\n",
    "        # Create a stage if not already done\n",
    "        cs.execute(\"CREATE OR REPLACE STAGE US_GZN_stage\")\n",
    "        \n",
    "        # Upload the .txt file to the stage\n",
    "        cs.execute(\"PUT file://2021_Gaz_zcta_national/2021_Gaz_zcta_national.txt @US_GZN_stage\")\n",
    "\n",
    "        # Create table if not exists (adjust the structure as per your .txt file's structure)\n",
    "        cs.execute(\"\"\"\n",
    "        CREATE OR REPLACE TABLE US_GZN_table (\n",
    "            GEOID INTEGER,\n",
    "            ALAND INTEGER,\n",
    "            AWATER INTEGER,\n",
    "            ALAND_SQMI FLOAT,\n",
    "            AWATER_SQMI FLOAT,\n",
    "            INTPTLAT FLOAT,\n",
    "            INTPTLONG FLOAT\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        # Copy the data from the stage into the table\n",
    "        cs.execute(\"\"\"\n",
    "            COPY INTO US_GZN_table\n",
    "            FROM @US_GZN_stage/2021_Gaz_zcta_national.txt\n",
    "            FILE_FORMAT = (TYPE = 'CSV' FIELD_DELIMITER='\\t' SKIP_HEADER = 1)\n",
    "        \"\"\")\n",
    "\n",
    "        print(\"Data loaded successfully into Snowflake table US_GZN_table\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "upload_txt_to_snowflake()\n",
    "\n",
    "#The US_GZN_table has 33.8k rows and 7 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7a- created closest_weather_station table for zipcodes with max temp values over selected date range (based on requirement in 7b)\n",
    "# The table was created by mapping the closest weather station from the NOAA Weather Station Index data to each geoid from the US Gazetteer data using longitude and latitude\n",
    "# The date range was picked based on time frame of the Monthly PO Data files cross checked against the min and max supplier transaction dates\n",
    "\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE closest_weather_station AS\n",
    "SELECT \n",
    "    b.geoid, \n",
    "    a.noaa_weather_station_id, \n",
    "    a.noaa_weather_station_name, \n",
    "    ST_DISTANCE(ST_MAKEPOINT(a.LONGITUDE, a.LATITUDE), ST_MAKEPOINT(b.INTPTLONG, b.INTPTLAT)) AS distance\n",
    "FROM \n",
    "    weather__environment.cybersyn.NOAA_WEATHER_STATION_INDEX AS a     \n",
    "JOIN \n",
    "    US_GZN_TABLE AS b\n",
    "    ON ST_DISTANCE(ST_MAKEPOINT(a.LONGITUDE, a.LATITUDE), ST_MAKEPOINT(b.INTPTLONG, b.INTPTLAT)) < 20000\n",
    "JOIN\n",
    "    (\n",
    "        SELECT DISTINCT noaa_weather_station_id\n",
    "        FROM weather__environment.cybersyn.NOAA_WEATHER_METRICS_TIMESERIES\n",
    "        WHERE VARIABLE = 'maximum_temperature'\n",
    "        AND DATE >= '2019-01-01' AND DATE <= '2022-05-31'\n",
    "    ) AS c\n",
    "    ON a.noaa_weather_station_id = c.noaa_weather_station_id\n",
    "QUALIFY \n",
    "    ROW_NUMBER() OVER(PARTITION BY b.geoid ORDER BY distance ASC) = 1\n",
    "\"\"\")\n",
    "\n",
    "#This table has 26.4k rows and 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7b - created materialized view, from a table, to store the supplier zip code weather data with daily high temperature values over the selected date range\n",
    "\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE supplier_zip_code_weather_temp AS \n",
    "SELECT\n",
    "    A.POSTALPOSTALCODE AS Zip_code,\n",
    "    C.DATE,\n",
    "    C.VALUE AS Daily_High_Temperature\n",
    "FROM SUPPLIER_CASE_TABLE AS A\n",
    "LEFT JOIN closest_weather_station AS B ON A.POSTALPOSTALCODE = B.GEOID\n",
    "LEFT JOIN weather__environment.cybersyn.NOAA_WEATHER_METRICS_TIMESERIES AS C \n",
    "ON B.NOAA_WEATHER_STATION_ID = C.NOAA_WEATHER_STATION_ID\n",
    "WHERE C.VARIABLE = 'maximum_temperature' AND DATE >= '2019-01-01' AND DATE <= '2022-05-31'\n",
    "GROUP BY Zip_code, C.DATE, Daily_High_Temperature\n",
    "ORDER BY Zip_code ASC, C.DATE ASC\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE MATERIALIZED VIEW supplier_zip_code_weather AS \n",
    "SELECT * FROM supplier_zip_code_weather_temp\n",
    "\"\"\")\n",
    "\n",
    "#This view has 9k rows and 3 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6b531d5210>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Create a materialized view of the supplier_case_table to join with the supplier_zip_code_weather view and purchase_orders_and_invoices view\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE MATERIALIZED VIEW supplier_case_view AS \n",
    "SELECT * FROM supplier_case_table\n",
    "\"\"\")\n",
    "\n",
    "#Create table \"Orders_suppliers_weather\" selecting all the relevant columns and dropping duplicates to view supplier case data and max temperature data for \n",
    "#Purchase orders with max temperature data for the given transaction date\n",
    "\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE Orders_suppliers_weather AS\n",
    "SELECT\n",
    "    A.PurchaseOrderID AS PurchaseOrderID,\n",
    "    A.SupplierID AS SupplierID,\n",
    "    A.OrderDate AS OrderDate,\n",
    "    A.ContactPersonID AS ContactPersonID,\n",
    "    A.ExpectedDeliveryDate AS ExpectedDeliveryDate,\n",
    "    A.IsOrderFinalized AS IsOrderFinalized,\n",
    "    A.LastEditedWhen AS LastEditedWhen,\n",
    "    A.PurchaseOrderLineID AS PurchaseOrderLineID,\n",
    "    A.StockItemID AS StockItemID,\n",
    "    A.OrderedOuters AS OrderedOuters,\n",
    "    A.Description AS Description,\n",
    "    A.ReceivedOuters AS ReceivedOuters,\n",
    "    A.PackageTypeID AS PackageTypeID,\n",
    "    A.ExpectedUnitPricePerOuter AS ExpectedUnitPricePerOuter,\n",
    "    A.LastReceiptDate AS LastReceiptDate,\n",
    "    A.IsOrderLineFinalized AS IsOrderLineFinalized,\n",
    "    A.Right_LastEditedBy AS Right_LastEditedBy,\n",
    "    A.Right_LastEditedWhen AS Right_LastEditedWhen,\n",
    "    A.POAmount AS POAmount,\n",
    "    A.SupplierTransactionID AS SupplierTransactionID,\n",
    "    A.TransactionTypeID AS TransactionTypeID,\n",
    "    A.PaymentMethodID AS PaymentMethodID,\n",
    "    A.SupplierInvoiceNumber AS SupplierInvoiceNumber,\n",
    "    A.TransactionDate AS TransactionDate,\n",
    "    A.AmountExcludingTax AS AmountExcludingTax,\n",
    "    A.TaxAmount AS TaxAmount,\n",
    "    A.TransactionAmount AS TransactionAmount,\n",
    "    A.OutstandingBalance AS OutstandingBalance,\n",
    "    A.FinalizationDate AS FinalizationDate,\n",
    "    A.IsFinalized AS IsFinalized,\n",
    "    A.SupplierTransactionLastEditedBy AS SupplierTransactionLastEditedBy,\n",
    "    A.SupplierTransactionLastEditedWhen AS SupplierTransactionLastEditedWhen,\n",
    "    A.Invoice_vs_quoted AS Invoice_vs_quoted,\n",
    "    B.\"SupplierName\" AS SupplierName,\n",
    "    B.SupplierCategoryID AS SupplierCategoryID,\n",
    "    B.PrimaryContactPersonID AS PrimaryContactPersonID,\n",
    "    B.AlternateContactPersonID AS AlternateContactPersonID,\n",
    "    B.DeliveryMethodID AS DeliveryMethodID,\n",
    "    B.PostalCityID AS PostalCityID,\n",
    "    B.\"SupplierReference\" AS SupplierReference,\n",
    "    B.\"BankAccountName\" AS BankAccountName,\n",
    "    B.\"BankAccountBranch\" AS BankAccountBranch,\n",
    "    B.BankAccountCode AS BankAccountCode,\n",
    "    B.BankAccountNumber AS BankAccountNumber,\n",
    "    B.BankInternationalCode AS BankInternationalCode,\n",
    "    B.PaymentDays AS PaymentDays,\n",
    "    B.InternalComments AS InternalComments,\n",
    "    B.\"PhoneNumber\" AS PhoneNumber,\n",
    "    B.\"FaxNumber\" AS FaxNumber,\n",
    "    B.\"WebsiteURL\" AS WebsiteURL,\n",
    "    B.DeliveryAddressLine1 AS DeliveryAddressLine1,\n",
    "    B.DeliveryAddressLine2 AS DeliveryAddressLine2,\n",
    "    B.DeliveryPostalCode AS DeliveryPostalCode,\n",
    "    B.DeliveryLocation AS DeliveryLocation,\n",
    "    B.PostalAddressLine1 AS PostalAddressLine1,\n",
    "    B.PostalAddressLine2 AS PostalAddressLine2,\n",
    "    B.PostalPostalCode AS PostalPostalCode,\n",
    "    B.LastEditedBy AS LastEditedBy,\n",
    "    B.ValidFrom AS ValidFrom,\n",
    "    B.ValidTo AS ValidTo,\n",
    "    C.Zip_code AS Zip_code,\n",
    "    C.Daily_High_Temperature AS Daily_High_Temperature\n",
    "    \n",
    "FROM purchase_orders_and_invoices AS A\n",
    "JOIN supplier_case_view AS B ON A.SupplierID = B.SupplierID\n",
    "JOIN supplier_zip_code_weather AS C ON B.PostalPostalCode = C.Zip_code AND A.TransactionDate = C.DATE\n",
    "\"\"\")\n",
    "\n",
    "#This table has 6k rows and 62 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close all connections :)\n",
    "cs.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
